# Yes, absolutely! The Superstore dataset (commonly used in Tableau and data analysis) is 
# **perfect for linear regression**. It contains numerical variables with clear relationships
# that can be modeled effectively. Here's how to get started:

## **Why Superstore Works Great for Linear Regression**
#- **Rich numerical data**: Sales, Profit, Discount, Quantity, Shipping Cost
#- **Categorical variables**: Can be encoded for regression
#- **Clear business relationships**: Sales vs. Profit, Discount vs. Sales, etc.
# - **Clean structure**: ~10K rows, minimal missing values



## **1. Common Linear Regression Examples with Superstore**

### **Example 1: Sales vs. Profit**

Target: Profit
Features: Sales

# **Expected**: Positive linear relationship (higher sales → higher profit)

### **Example 2: Discount Impact on Sales**

Target: Sales
Features: Discount

# *Expected**: Negative relationship (higher discount → lower sales)

### **Example 3: Multiple Regression**

Target: Profit
Features: Sales, Discount, Quantity, Shipping Cost



## **2. Python Implementation (Complete Code)**


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import warnings
warnings.filterwarnings('ignore')

# Load Superstore data (download from Tableau Public or use sample)
# Assuming you have 'superstore.csv'
df = pd.read_csv('superstore.csv')

# Basic preprocessing
df['Profit'] = pd.to_numeric(df['Profit'], errors='coerce')
df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')
df['Discount'] = pd.to_numeric(df['Discount'], errors='coerce')
df = df.dropna(subset=['Profit', 'Sales', 'Discount'])

print(f"Dataset shape: {df.shape}")
print(df[['Sales', 'Profit', 'Discount']].describe())


### **Simple Linear Regression: Sales → Profit**


# Simple Linear Regression
X = df[['Sales']]
y = df['Profit']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Metrics
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"R² Score: {r2:.3f}")
print(f"RMSE: {rmse:.2f}")
print(f"Slope (Sales coefficient): {model.coef_[0]:.3f}")
print(f"Intercept: {model.intercept_:.2f}")


### **Multiple Linear Regression**


# Multiple features
X_multi = df[['Sales', 'Discount', 'Quantity']]
y_multi = df['Profit']

X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(
    X_multi, y_multi, test_size=0.2, random_state=42
)

model_multi = LinearRegression()
model_multi.fit(X_train_m, y_train_m)
y_pred_multi = model_multi.predict(X_test_m)

r2_multi = r2_score(y_test_m, y_pred_multi)
print(f"Multiple R² Score: {r2_multi:.3f}")
print("Coefficients:", dict(zip(X_multi.columns, model_multi.coef_)))



## **3. Visualization**


# Plot 1: Actual vs Predicted
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('Actual Profit')
plt.ylabel('Predicted Profit')
plt.title(f'Actual vs Predicted (R² = {r2:.3f})')

# Plot 2: Sales vs Profit with regression line
plt.subplot(1, 2, 2)
sns.regplot(x='Sales', y='Profit', data=df.sample(1000), scatter_kws={'alpha':0.5})
plt.title('Sales vs Profit Trend')

plt.tight_layout()
plt.show()




## **4. Expected Results**

Simple Regression (Sales → Profit):
- R²: ~0.25-0.30 (moderate fit)
- Slope: ~0.20 (for every $1 sales increase, profit ↑ $0.20)

Multiple Regression:
- R²: ~0.35-0.40 (better fit)




## **5. Quick Dataset Download**
If you don't have the data:

# Get sample Superstore data
url = "https://github.com/vivek468/Superstore-Dataset/raw/master/Superstore.csv"
df = pd.read_csv(url)




## **6. Advanced Extensions**
# - **Categorical encoding**: One-hot encode Region, Category
# - **Polynomial features**: Sales² for non-linear relationships
# - **Interaction terms**: Sales × Discount
- **Regularization**: Ridge/Lasso for feature selection


## **Sample Output You'll Get**

Dataset shape: (9994, 21)
R² Score: 0.282
RMSE: 1123.45
Slope: 0.198
Multiple R² Score: 0.384
# =============================================================================

**Ready to run?** Just download the Superstore CSV and execute the code above. 
You'll have working linear regression models in **5 minutes**!